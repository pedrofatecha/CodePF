# DuckDB, Polars and Pandas performance comparison

This repo contains code that highlights that `pandas`, despite its maturity and importance to the Python data science ecosystem, is **far** slower than either `polars` or `duckdb`, while being less efficient with memory usage, because it materializes the entire data into memory (as opposed to `polars` and `duckdb` which are lazy and only materialize the data when needed).

* `pandas` is a popular Python DataFrame library for data manipulation and analysis, whose internals are in C++ -- the latest version of `pandas` (2.x) is used in this benchmark.
* `polars` is a newer DataFrame library for data manipulation and analysis, whose internals are in Rust, and is far more amenable to multi-threading DataFrame ops than `pandas`.
* `duckdb` is a high-performance embedded database that can be queried via a rich SQL dialect. Its core is written in C++, and is designed to be fast, reliable and easy to use, and very amenable to transformation to either `pandas` or `polars`

Both `polars` and `duckdb` (being written in Rust and C++ respectively) have had [ample opportunity to learn from](https://twitter.com/datapythonista/status/1692452584785580111) the pain points of `pandas` and the general PyData ecosystem over the years, allowing them to leverage lessons from modern database theory and the power of the Apache Arrow ecosystem.

## Setup

Install a Python virtual environment and then install the dependencies via `requirements.txt` as follows.

```sh
python3 -m venv .duckdbenv  # python -> python 3.10+
source .duckdbenv/bin/activate
python3 -m pip install -U pip wheel  # Upgrade pip and install the wheel package first
python3 -m pip install -r requirements.txt
```

## Generate dataset

The benchmark task is basically to use any one of `pandas`, `polars`, or `duckdb` to generate an artificial dataset of persons, the companies they held work positions in, and their locations. The input dataset we begin with is the [7+ million companies dataset](https://www.kaggle.com/datasets/peopledatalabssf/free-7-million-company-dataset) from Kaggle, which is preprocessed into a parquet file.

The dataset is generated by randomly sampling from the input dataset, and then randomly generating positions for each person with repetition, allowing a one-to-many relationship (the same person and multiple company positions).

## Benchmark

The example results and timing benchmarks to generate the full dataset are shown below. The benchmarks are run using the `pytest-benchmark` library which itself depends on `pytest`.

### Conditions

* Raw dataset being generated contains 1M persons and 10M positions at companies that these 1M persons have held
* Macbook Air M2, 16 GB RAM
* Average of 3 runs (for each of `pandas`, `polars` and `duckdb`)
* Garbage collector timing disabled during benchmark

### Results

```sh
cd perf_study
```


```sh
python3 -m pytest benchmark.py --benchmark-min-rounds=3 --benchmark-disable-gc

```
Wait ~ 5 mins

### Results

Average over 3 runs (on my machine MacBook Air M2, 16GB RAM):


| Approach | Time (sec) | Runtime increase vs. DuckDB
|---------|----------: | --------------:
| `duckdb` | 4.9 | -
| `polars` | 6.49 | +32%
| `pandas` | 21.84 | +345%

As can be seen, `duckdb` is the fastest ðŸ”¥, followed cloesly by `polars`. `pandas` is the slowest by a factor of ~4x when compared to DuckDB.
